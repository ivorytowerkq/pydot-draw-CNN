{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (1600, 50, 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4a9cd425e048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[1;31m#测试模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\python\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\python\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\python\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (1600, 50, 50)"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "from numpy import *\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Input,Dense\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "from keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D,BatchNormalization\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "from keras.layers import Convolution2D, MaxPooling2D,Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage import io, transform\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import misc\n",
    "\n",
    "c=np.load('icar(l).npz')\n",
    "train_data=c['train_data']\n",
    "train_labels=c['train_labels']\n",
    "test_data=c['test_data']\n",
    "test_labels=c['test_labels']\n",
    "\n",
    "\n",
    "train_data=train_data.astype(np.float16)/255\n",
    "test_data=test_data.astype(np.float16)/255\n",
    "#将标签量进行转化\n",
    "train_labels=np_utils.to_categorical(train_labels)\n",
    "test_labels=np_utils.to_categorical(test_labels)\n",
    "\n",
    "def net2(nb_classes):\n",
    "#model = Sequential()\n",
    "    img_input = Input(shape=(50,50,1))\n",
    "\n",
    "    conv1=Conv2D(filters=16, kernel_size=(5,5), padding='same', activation='relu')(img_input)\n",
    "    \n",
    "    conv1= BatchNormalization()(conv1)\n",
    "\n",
    "    maxpool1=MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "\n",
    "    conv2=Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu')(maxpool1)\n",
    "    \n",
    "    conv2= BatchNormalization()(conv2)\n",
    "\n",
    "    maxpool2=MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "\n",
    "    conv3=Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu')(maxpool2)\n",
    "    \n",
    "    conv3= BatchNormalization()(conv3)\n",
    "\n",
    "    maxpool3=MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "\n",
    "    conv4=Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')(maxpool3)\n",
    "    \n",
    "    conv4= BatchNormalization()(conv4)\n",
    "\n",
    "    maxpool4=MaxPooling2D(pool_size=(2,2))(conv4)\n",
    "\n",
    "    fire_squeeze = Convolution2D(\n",
    "        16, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire2_squeeze')(maxpool4)\n",
    "    \n",
    "    fire_expand1 = Convolution2D(\n",
    "        64, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire2_expand1')(fire_squeeze)\n",
    "    \n",
    "    fire_expand2 = Convolution2D(\n",
    "        64, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire2_expand2')(fire_squeeze)\n",
    "    \n",
    "    merge = Concatenate(axis=1)([fire_expand1, fire_expand2])\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(merge)\n",
    "    \n",
    "    x = Dense(nb_classes, activation='softmax')(x)\n",
    "   \n",
    "    model = Model(img_input, x, name='net2')\n",
    "    return model\n",
    "\n",
    "    #GlobalAveragePooling2D()(x)\n",
    "    # model.add(Dense(120, activation='relu'))\n",
    "\n",
    "    # model.add(Dense(84, activation='relu'))\n",
    "\n",
    "    #model.add(Dense(4, activation='softmax'))\n",
    "nb_classes=4\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model=net2(nb_classes)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(train_data, train_labels,validation_split=0.2, batch_size=32, epochs=20, verbose=1, shuffle=True)\n",
    "\n",
    "#测试模型\n",
    "preds = np.argmax(model.predict(test_data), axis=1)\n",
    "test_labels = np.argmax(test_labels, axis=1)\n",
    "print (accuracy_score(test_labels, preds))\n",
    "\n",
    "#记录模型日志\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False)\n",
    "#画模型准确率曲线和损失率曲线\n",
    "plt.plot(epochs, acc, 'ro:', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'bo:', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'ro:', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'bo:', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
